# ğŸ¤– AI-Enabled Job Resume Intelligence Platform

A full-stack AI-powered platform for analyzing job descriptions, matching resumes, ranking candidates, and providing intelligent chat capabilities using RAG (Retrieval Augmented Generation).

## âœ¨ Features

- ğŸ“‹ **Job Analysis**: Extract skills from job descriptions using AI
- ğŸ“„ **Resume Processing**: Upload and analyze PDF/TXT resumes
- ğŸ¯ **Smart Matching**: Calculate skill match percentage
- ğŸ† **Candidate Ranking**: Automatically rank top 10 candidates
- ğŸ’¬ **AI Chat**: Ask questions about resumes using RAG
- ğŸ§  **Conversation Memory**: Persistent chat history
- ğŸ†“ **Zero Cost**: Uses free local AI (Ollama)

## ğŸ› ï¸ Tech Stack

### Frontend
- **React 19.2** - UI library
- **Vite 7.x** - Build tool & dev server
- **Tailwind CSS 3.4** - Utility-first styling
- **Axios** - HTTP client
- **Lucide React** - Icons

### Backend
- **Node.js v18+** - Runtime with ES modules
- **Express 4.18** - Web framework
- **Multer** - File upload middleware
- **pdf-parse** - PDF text extraction
- **Cheerio** - HTML parsing for job URL scraping
- **Natural** - Keyword extraction fallback

### AI/ML
- **Ollama** - Local LLM (llama3.2:3b)
- **LangChain 0.3.x** - AI orchestration framework
- **nomic-embed-text** - Embeddings (768D vectors)
- **Custom Vector Store** - In-memory cosine similarity search

## ğŸ“‹ Prerequisites

Before you begin, ensure you have:

- **Node.js** v18 or higher ([Download](https://nodejs.org/))
- **Ollama** ([Download](https://ollama.ai/))
- **Git** (optional)

## ğŸš€ Quick Start

### 1. Install Ollama & Models

```bash
# Install Ollama from https://ollama.ai

# Pull required models
ollama pull llama3.2:3b
ollama pull nomic-embed-text

# Verify installation
ollama list
```

### 2. Clone or Download Project

```bash
git clone <repository-url>
cd resume-intelligence-platform
```

### 3. Backend Setup

```bash
cd backend

# Install dependencies
npm install

# Create .env file (Windows)
copy .env.example .env
# Or (Mac/Linux)
cp .env.example .env

# Create required directories (Windows)
mkdir uploads
# Or (Mac/Linux)
mkdir -p uploads data/vectors

# Start backend server
npm run dev
```

Backend will run on `http://localhost:5000`

### 4. Frontend Setup

```bash
cd ../frontend
 (Windows)
copy .env.example .env
# Or (Mac/Linux)
# Install dependencies
npm install

# Create .env file
cp .env.example .env

# Start frontend
npm run dev
```

Frontend will run on `http://localhost:5173`

### 5. Access Application

Open your browser and navigate to:
```
http://localhost:5173
```

## ğŸ“ Project Structure

```
resume-intelligence-platform/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ config/         # Configuration files
â”‚   â”‚   â”œâ”€â”€ controllers/    # Request handlers
â”‚   â”‚   â”œâ”€â”€ middleware/     # Express middleware
â”‚   â”‚   â”œâ”€â”€ models/         # Data models
â”‚   â”‚   â”œâ”€â”€ routes/         # API routes
â”‚   â”‚   â”œâ”€â”€ services/       # Business logic
â”‚   â”‚   â”œâ”€â”€ utils/          # Utility functions
â”‚   â”‚   â””â”€â”€ server.js       # Entry point
â”‚   â”œâ”€â”€ uploads/            # Temporary file storage
â”‚   â”œâ”€â”€ data/vectors/       # Vector embeddings
â”‚   â””â”€â”€ package.json
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ components/     # React components
    â”‚   â”œâ”€â”€ services/       # API client
    â”‚   â”œâ”€â”€ utils/          # Helper functions
    â”‚   â”œâ”€â”€ App.jsx         # Main app
    â”‚   â””â”€â”€ main.jsx        # Entry point
    â””â”€â”€ package.json
```

## ğŸ¯ How to Use

### 1. Create a Job

1. Go to "Job Description" tab
2. Enter job title and description
3. Click "Analyze Job & Extract Skills"
4. AI extracts required skills automatically

### 2. Upload Resume

1. Go to "Upload Resume" tab
2. Drag & drop or click to upload PDF/TXT
3. System automatically matches with current job
4. View match percentage and missing skills

### 3. View Rankings

1. Go to "Top Resumes" tab
2. See all resumes ranked by match percentage
3. View detailed breakdown for each candidate

### 4. Chat with Resume

1. Go to "Chat with Resume" tab
2. Ask questions about the resume
3. AI answers using RAG (retrieves relevant sections)
4. Conversation history is maintained

## ğŸ“Š Example Queries

**Job Analysis:**
- "Senior React Developer with 5+ years experience..."
- Extracts: React, JavaScript, Node.js, TypeScript, etc.

**Resume Chat:**
- "What are the candidate's React skills?"
- "How many years of experience?"
- "Does the candidate have leadership experience?"

## ğŸ”§ Configuration

### Backend (.env)
```env
PORT=5000
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
FRONTEND_URL=http://localhost:5173
MAX_FILE_SIZE=10485760
```

### Frontend (.env)
```env
VITE_API_URL=http://localhost:5000/api
```

## ğŸ› Troubleshooting

### Ollama Not Running
```bash
# Check if Ollama is running
curl http://localhost:11434/api/tags

# Mac/Linux
lsof -ti:5000 | xargs kill -9

# Windows
netstat -ano | findstr :5000
# Note the PID, then:
taskkill /PID <PID> /F

### Port Already in Use
```bash
# Kill process on port 5000
lsof -ti:5000 | xargs kill -9  # Mac/Linux
netstat -ano | findstr :5000   # Windows
```

### CORS Er`uploads/` directory exists in backend folder
- Verify file size < 10MB (configurable in .env)
- Ensure file format is PDF or TXT only
- Check backend console for detailed error messages

### Slow AI Responses
- First API call loads the model (10-30s is normal)
- Subsequent calls are much faster (5-10s)
- Ensure Ollama is running: `ollama list`
- Consider using a smaller model if neededng on port 5173
- Check FRONTEND_URL in backend/.env

### Upload Errors
- Check if uploads/ directory exists
- Verify file size < 10MB
- Ensure PDF or TXT format

## ğŸ“ˆ Performance

**Optimized Settings** (num_predict: 80, num_ctx: 2048):
- **First AI Call**: 10-30 seconds (model loading + inference)
- **Subsequent Calls**: 5-10 seconds (cached model)
- **Skill Extraction**: 5-15 seconds per document
- **Resume Upload**: 10-20 seconds (parsing + embedding)
- **Chat Response**: 3-8 seconds (RAG retrieval + generation)
- **Match Calculation**: <1 second (pure computation)

## ğŸ” Security Notes

**Current Implementation** (Prototype):
- No authentication
- In-memory storage
- No data encryption

**For Production**:
- Add JWT authentication
- Use PostgreSQL/MongoDB
- Implement HTTPS
- Add rate limiting
- Sanitize inputs

## ğŸš¦ API Endpoints

### Jobs
```
POST   /api/jobs              - Create job
GET    /api/jobs              - Get all jobs
GET    /api/jobs/:id          - Get job by ID
DELETE /api/jobs/:id          - Delete job
```

### Resumes
```
POST   /api/resumes/upload                    - Upload resume
GET    /api/resumes/:id                       - Get resume
GET    /api/resumes/:id/compare/:jobId        - Compare with job
GET    /api/resumes/ranking/job/:jobId        - Get top 10 for job
```

### Chat
```
POST   /api/chat                     - Send message
GET    /api/chat/sessions/:id        - Get chat history
DELETE /api/chat/sessions/:id        - Clear history
```

## ğŸ“ Assignment Criteria Met

âœ… **AI Orchestration**: Multiple AI operations coordinated
âœ… **RAG Implementation**: Complete retrieval-augmented generation
âœ… **Memory-Aware Systems**: Persistent conversation memory
âœ… **MERN + LLM Integration**: Full stack with AI
âœ… **Core Features**: All 7 required features implemented
âœ… **Extended AI**: Top 10 ranking, chat, memory
âœ… **Free Solution**: Zero cost with Ollama

## ğŸ“ License

This project is for educational purposes.

## ğŸ¤ Contributing

Contributions welcome! Feel free to submit pull requests.

## ğŸ“§ Support

For issues or questions, please open a GitHub issue.

---

**Built with â¤ï¸ using React, Node.js, and Ollama**